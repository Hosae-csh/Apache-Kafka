# Apache Kafka

---

프로듀서가 데이터를 파티션으로 보냄 각각의 파티션 모두에게 보내는게 아니라 파티션중 하나에게 보내는거임

그리고 컨슈머는 파티션에 있는 데이터를 FIFO방식으로 가져옴

컨슈머가 파티션에서 데이터를 가져간다고해서 파티션에서 데이터가 사라지는게아님 이게 특징임

컨슈머는 커밋을 통해서 파티션의 몇번째 데이터까지 가져갓는지 기록

---

프로듀서

파티션

컨슈머

---

![Untitled](Apache%20Kafka%20398784983c2c4239bc327338e792511f/Untitled.png)

![Untitled](Apache%20Kafka%20398784983c2c4239bc327338e792511f/Untitled%201.png)

![Untitled](Apache%20Kafka%20398784983c2c4239bc327338e792511f/Untitled%202.png)

각각의 브로커는 카프카 프로세서라고 볼 수 있음

프로듀서에서 데이터를 보내게되면 각각의 브로커에 메시지가 저장됨

각각의 브로커의 데이터 처리량에는 한계가있음 이때 브로커를 계속 추가할 수 있음

인스턴스추가하는 개념

---

### 초기 빅데이터 플랫폼

애플리케이션 → 원천 데이터 → 파생 데이터 → 서빙 데이터 → 사용자

### 람다 아키텍쳐

![Untitled](Apache%20Kafka%20398784983c2c4239bc327338e792511f/Untitled%203.png)

스피드 레이어에 카프카가 위치해 있다고 보면됨

람다 단점 :  데이터를 한번에 모아서 처리하는 배치 레이어와 실시간 데이터를 처리하는 스피드 레이어의 로직을 따로 짜야해서 두개를 융합하여 처리하여야할 일이있을때 유연하지 못함

### 카파 아키텍처

![Untitled](Apache%20Kafka%20398784983c2c4239bc327338e792511f/Untitled%204.png)

배치 레이어에서 하던일들을 스피드레이어에서 모두 할 수 있다.(Kafka 를 이용해서)

카프카에서는 배치 데이터를 함께 처리하기 위해 로그(레코드), 배치 데이터 스냅샷, 변환 기록 로그를 사용한다.

변환기록 로그에는 timestamp가 필요하며 로그의 각 레코드에는 timestamp 가 있어 몇시 부터 몇시까지의 데이터를 가져와서 배치로 처리해라 이런식으로 데이터 사용이 가능하다.

배치 데이터

스트림 데이터

배치 데이터 처리(하둡)

스트림 데이터를 배치 데이터로 사용하는방법(카프카) :Materialized View

### 스트리밍 데이터 레이크

2020년에 제안된 아키텍처 현재는 실현 힘듬

실현하기 위해 자주사용하는 데이터 자주접근하지 않느 데이터를 나누는 등 계속 개선중 (현재 지원은 안함)

---

## 카프카 생태계

![Untitled](Apache%20Kafka%20398784983c2c4239bc327338e792511f/Untitled%205.png)

**프로듀서**가 데이터를 **토픽**에 넣어주고 **컨슈머**가 토픽의 데이터를 가져감

**스트림즈**는 컨슈머로 보내기전에 토픽을 가공(?)하고싶을때  가공하여 새로운 토픽생성

커넥트(소스) : 프로듀서 역할

커넥트(싱크) : 컨슈머 역할

커넥트는 클러스터로 운영, 파이프라인을 템플릿형태로 반복적으로 여러번 생성할 수 있음

카프카 브로커, 클러스터, 주키퍼

브로커를 묶어놓은 클러스터를 사용하려면 주키퍼가 꼭필요함

3.0버전부터는 주키퍼 없이도 가능하지만 아직 상용되지는 않았음

주키퍼를 모아놓은것이 주키퍼 앙상블

컨트롤러

데이터 삭제 : 시간이나 용량에따라, 특수상황에서 compact, 로그 세그먼트 단위로 삭제, 콕콕찝어서 어디어디부분만 삭제 불가

컨슈머 오프셋 저장

어디까지 처리햇는지가 commit인데 이 commit의 offset을 __consumer_offsets 토픽에 저장

그룹 코디네이터

컨슈머 중에 장애가 생긴 컨슈머가 있으면 장애가 생긴 컨슈머가 처리하던 파티션을 다른 컨슈머에게 재할당

---

### 로그와 세그먼트

메시지 = 레코드

프로듀서가 레코드를 만들어서 브로커에게 전송하면 active segment 로그에 추가로 데이터가 쌓임

로그의 파일명은 시작점 offset

bytes(기본값 1GB) 1기가 다 안차 더라도 시간기준으로 넘어갈 수 있음(기본값 7일)

액티브 세그먼트는 삭제 대상에 포함안됨

---

### 세그먼트와 삭제 주기

retention.ms  : 세그먼트를 보유할 최대 기간. 기본값은 7일

retention.bytes :  파티션당 로그 적재 바이트 값 기본값은 -1(지정하지 않음)

log.retention.check.interval.ms : 세그먼트가 삭제 영역에 들어왔는지 ( 기간이 지났는지 or 적재량이 넘었는지) 확인하는 간격, 기본 값은 5분

디스크 용량에 따라 각 값들을 잘 세팅하고 확인하는 간격도 잘 조절해야됨.

### 세그먼트의 삭제

카프카에서 데이터는 세그먼트 단위로 삭제하기 떄문에

로그단위(레코드단위)로 개별 삭제는 불가

브로커로 넘어온 데이터는 삭제,수정이 불가하기 떄문에

프로듀서에서 브로커(topic)에게 레코드(data)를 넘길때 컨슈머가 처리할때 이상이 없는 데이터인지

밸리데이션이 꼭필요

### cleanup.policy=compact

key값 기준으로 가장 최근것만 남기는것

### 테일/헤드 영역, 클린/더티 로그

압축이 이미 한번 된 애들을 모아논곳이 클린로그 → 테일영역

### 브로커의 역할 - 복제(Replication)

목적 : 데이터 유실을 방지하기 위해

---

브로커

클러스터

주키퍼

카프카의 특징

- 높은 처리량
- 확장성
- 영속성
- 고가용성